{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Import IKEA Furniture Data-Set](#Import-IKEA-Furniture-Data-Set)\n",
    "- [Create a Random Forest](#Create-a-Random-Forest)\n",
    "    - [Create a First Version of a Random Forest](#Create-a-First-Version-of-the-Random-Forest)\n",
    "    - [First Improvements of the Random Forest](#First-Improvements-of-the-Random-Forest)\n",
    "    - [Final Version of the Random Forest](#Final-Version-of-the-Random-Forest)\n",
    "    - [Further Investigations of the Random Forest Model](#Further-Investigations-of-the-Random-Forest-Model)\n",
    "- [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot') # emulate pretty r-style plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import IKEA Furniture Data-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load IKEA_df\n",
    "with open('Data/IKEA_df.p', 'rb') as df:\n",
    "    IKEA_df = pickle.load(df)\n",
    "\n",
    "IKEA_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load learn_df\n",
    "with open('Data/learn_df.p', 'rb') as df:\n",
    "    learn_df = pickle.load(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get labels\n",
    "label = IKEA_df['category'].unique()\n",
    "label = label.tolist()\n",
    "print('labels:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of features that can be used as predictors\n",
    "t = learn_df.drop(columns = ['category','category_num']).shape[1]\n",
    "print('Overall, there are '+str(t)+' features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Random Forest\n",
    "We first take look at an example calssifier, it is almost a standard random forest classifier apart from that we set min_samples_leaf= 5.\n",
    "\n",
    "**Note**: the exact value of overall accuracy, accuracy in confusion matrix and even ranking of feature importance might slightly differ from the ones written in comments because of randomness in algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Create a First Version of a Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OOB score shows that this  random forest classifier fit the training data well. Indeed, it estimates the accuracy of predction on test data well, since the OOB score and accuracy are almost the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into test and training dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(learn_df.drop(columns = ['category','category_num']), \\\n",
    "                                                    learn_df['category_num'], random_state=1)\n",
    "\n",
    "rf =  RandomForestClassifier(min_samples_leaf= 5,oob_score=True)\n",
    "rf_est = rf.fit(X_train,y_train)\n",
    "y_pred =  rf.predict(X_test)\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "oob = rf.oob_score_\n",
    "# Note : this acuracy is not weighted by sample size!!! \n",
    "print('Overall acuracy of all category: ' +str(a))\n",
    "print('Out-of-Bag score:' +str(oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : this overall acuracy is not weighted by sample size , so even for a category with a small size the performance is totally trash, we still have an acceptable overall acuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check feature importance\n",
    "feature_impo = pd.Series(data=rf_est.feature_importances_, index=list(X_train.columns))\n",
    "feature_impo = feature_impo.sort_values(axis=0, ascending=False)\n",
    "feature_impo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "figip,axip = plt.subplots(1,1, figsize=(8,6))\n",
    "feature_impo.plot(kind='barh', ax=axip)\n",
    "axip.set_xlabel('Importance')\n",
    "axip.set_ylabel('Feature')\n",
    "axip.set_title('Feature importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets check the confusion matrix to examine the acuracy for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cm =  confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# number of smaples actually belong to each category\n",
    "cm_sum = cm.sum(axis = 1)\n",
    "\n",
    "cm1 = np.zeros((17,17))\n",
    "\n",
    "# confusion matrix divided by  number of samples in test set belongs to each category \n",
    "for k in range(17):\n",
    "    cm1[k,:] = cm[k,:]/cm_sum[k]\n",
    "\n",
    "# confusion_matrix normalized \n",
    "cm_df = pd.DataFrame(cm1,index = label, columns=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot confusion matrix \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(cm_df, annot=True, linewidths=.5,ax=ax,fmt='.2f',cmap = cmap)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.figure.savefig('Figures/Random_Forest/RF_CM_1.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An analysis of this confusion matrix will be given later; toghether with next plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Improvements of the Random Forest\n",
    "First improvement by further selection of the features by only keeping the important features.\n",
    "From feature importance report we get that size data  play the  great role in prediction, as we asuumed before in feature analysis. In addition name of the items is also important. Lets see what happens if we just keep those 5 top features with importance  larger than around 5%. We remove the feature **sellable online**, **item_id** and **other_colors**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need item_id and category in dataframe for other use, not for training\n",
    "learn1 = ['item_id','height','depth','width','name','designer','category','category_num']\n",
    "learn_df1 = learn_df[learn1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into test and training data-set\n",
    "X_train, X_test, y_train, y_test = train_test_split(learn_df1.drop(columns = ['item_id','category','category_num']), \\\n",
    "                                                    learn_df1['category_num'], random_state=1)\n",
    "# create random forest\n",
    "rf =  RandomForestClassifier(min_samples_leaf= 5,oob_score=True)\n",
    "rf_est = rf.fit(X_train,y_train)\n",
    "y_pred =  rf.predict(X_test)\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "oob = rf.oob_score_\n",
    "print('Overall acuracy of all category: ' +str(a))\n",
    "print('Out-of-Bag score: ' +str(oob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall acuracy increased from about 80% to 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cm =  confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# number of smaples actually belong to each category\n",
    "cm_sum = cm.sum(axis = 1)\n",
    "\n",
    "cm1 = np.zeros((17,17))\n",
    "\n",
    "# confusion matrix divided by  number of samples in test set belongs to each category \n",
    "for k in range(17):\n",
    "    cm1[k,:] = cm[k,:]/cm_sum[k]\n",
    "\n",
    "# confusion_matrix normalized \n",
    "cm_df = pd.DataFrame(cm1,index = label, columns=label)\n",
    "\n",
    "#plot confusion matrix \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(cm_df, annot=True, linewidths=.5,ax=ax,fmt='.2f',cmap = cmap)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.figure.savefig('Figures/Random_Forest/RF_CM_2.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the both confusion matrix we get that through feature selection,  we increase the overall accuracy at about1%  in the way that the accuracy for category Nursury furniture have been significantly increased by 10% respectly. And it is clear that the category with the worst performance: Room diveider with 0%, Sideboards & console tables with 0%, then Bar furniture 42%. Those are exactly the category with smallest sample size in whole dataset. As we mentioned above we can replicate  those samples to make it to a  ralative balanced multi-class classification task. The category TV & media furniture perform also not good, 30% TV& medianfurnitures have been predicted as Book cases & shelving unit. Considering the feature importance and boxplot of height and depth, we find that those two category have really simillar distribution shown in boxplot of those top 2 features.No wonder then.To our supprise, category Trolleys ,of which samples size is just 28, has the outstanding performance. We did not find the obvious clue from  its size  and price. We take look at the data set and find  the option for its name and designer is restricted and this might be the reason.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Version of the Random Forest\n",
    "Improve the results by replicating the samples for the categories with a small sample size. This is the case for the following categories: **Room dividers** and **Sideboards, buffets & console tables**.\n",
    "The categories with small sample sizes in the dataset are replicated in order to make this multi class classification task be relativly balanced. As the results will prove, the accuracy of the model can be increased significantly by doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#recall the sample size of each category\n",
    "size_df = learn_df1.groupby('category').size().reset_index(name='size')\n",
    "size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# careful here the order of the labels somehow changed compared to the list 'label' above. The order of TV & median furniture\n",
    "# tables& dsks and trollyes somehow echanged as can be seen below . Thus, we cannot use the list label to display the correct order of \n",
    "# column names in this section.\n",
    "label1 =size_df['category'].tolist()\n",
    "if label != label1:\n",
    "    print('label does not equal label1. In the following, therefore label1 will be used.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "label_size = size_df['size'].tolist()\n",
    "label_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_df2 = learn_df1.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using label1 instead of label!\n",
    "#print(learn_df2.shape[0])\n",
    "for k in range(17):\n",
    "    temp_df = learn_df1[learn_df1['category'].str.contains(label1[k])] \n",
    "    #print('original size' + str(temp_df.shape[0]))\n",
    "    #print('label_size' +str(label_size[k]))\n",
    "    tt = round(max(label_size)/label_size[k]) -1\n",
    "    #print('to replicate' + str(tt))\n",
    "    if tt > 0:\n",
    "        temp_df1 = pd.concat([temp_df]*tt, ignore_index=True)\n",
    "        #print('df_repl size' +str(temp_df1.shape[0]))\n",
    "        learn_df2 = pd.concat([learn_df2, temp_df1] , ignore_index=True)\n",
    "        #print(learn_df2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# old dataset imbalanced\n",
    "size_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#new relative balanced data set with duplicated samples\n",
    "size_df2 = learn_df2.groupby('category').size().reset_index(name='size')\n",
    "size_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data-set has been modified, the samples are relatively balanced - even though there are many duplicated samples for the categories that only had very few samples before.\n",
    "Thus in a next step, the final version of the random forest can be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(learn_df2.drop(columns = ['item_id','category','category_num']), \\\n",
    "                                                    learn_df2['category_num'], random_state=1)\n",
    "rf =  RandomForestClassifier(min_samples_leaf= 5)\n",
    "rf_est = rf.fit(X_train,y_train)\n",
    "y_pred =  rf.predict(X_test)\n",
    "a = accuracy_score(y_test, y_pred)\n",
    "print('Overall acuracy of all category: ' +str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the replicated samples, we were able to increase the overall accuracy from about 82% to 89%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cm =  confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# number of smaples actually belong to each category\n",
    "cm_sum = cm.sum(axis = 1)\n",
    "\n",
    "cm1 = np.zeros((17,17))\n",
    "\n",
    "# confusion matrix divided by  number of samples in test set belongs to each category \n",
    "for k in range(17):\n",
    "    cm1[k,:] = cm[k,:]/cm_sum[k]\n",
    "\n",
    "# confusion_matrix normalized \n",
    "cm_df = pd.DataFrame(cm1,index = label, columns=label)\n",
    "\n",
    "#plot confusion matrix \n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(cm_df, annot=True, linewidths=.5,ax=ax,fmt='.2f',cmap = cmap)\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('Actual')\n",
    "ax.figure.savefig('Figures/Random_Forest/RF_CM_3.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an almost perfect diagonal matrix we desired. Through repeating samples to make size of each category  balanced,  the acuracy of prediction for Bar funiture has been increased from 42% to 95% ,  for Room dividers from 0% to 100%,  for Sideboards, buffets & console rable from 0% to 100% etc. It is still hard for the algorithm to distinguish nursery furniture from children furniture.The reason is clear that consering two the immportant features: height and depth, the distribution are almost the same in the box plot. 20% of Carbinet& cupboards furniture have beed predicted as TV & median furniture, the main reason is that both have almost same distributino of depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_impo = pd.Series(data=rf_est.feature_importances_, index=list(X_train.columns))\n",
    "feature_impo = feature_impo.sort_values(axis=0, ascending=False)\n",
    "feature_impo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with replicated samles in data set , the feature name(former) becomes the most important feature, followed by height (former top1) and depth(former top2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Investigations of the Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we try out different parameter settings to see if we can get better predictions. After trail and error we keep the following parameter sets to show the impact of those parameters. Best minimum samples in leaf  is  1 (we set 5 before), if increase the size the overall predictions accuracy goes down. Normally the acurracy increase with the size of forest until  reaching certain threshold and the accuracy become stable. In total those parameters just influence the overall acuracy less than 0.01, and the best overall accuracy witih random forest is about 90.27% for minimum_samples_leaf =1, n_tree = 400. Here we won't check the single confusion matrix, since the dataset is now balanced w.r.t sample size of each category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(n_tree, min_leaf, learn_df):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(learn_df2.drop(columns = ['category_num','category','item_id']), \\\n",
    "                                                        learn_df2['category_num'], random_state=1)\n",
    "    start_time = time.time()\n",
    "    rf =  RandomForestClassifier(n_estimators = n_tree,criterion = 'gini', min_samples_leaf = min_leaf,random_state =1,\\\n",
    "                                 oob_score=True,warm_start=True)\n",
    "    rf.fit(X_train,y_train)\n",
    "    y_pred =  rf.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    #print('time consumption: '+ str(end_time - start_time))\n",
    "    # overall acuracy\n",
    "    a = accuracy_score(y_test, y_pred)\n",
    "    oob = rf.oob_score_\n",
    "    return a, oob\n",
    "# uncomment all below to check the confusion matrix for each loop\n",
    "#     # confusion matrix   \n",
    "#     m =  confusion_matrix(y_test, y_pred)\n",
    "#     #calculate total number of samples of each category in X_test\n",
    "#     m_sum = m.sum(axis = 1)\n",
    "#     m1 = np.zeros((17,17))\n",
    "#     for k in range(17):\n",
    "#          m1[k,:] = m[k,:]/m_sum[k]\n",
    "#     m_df = pd.DataFrame(m1,index = label, columns=label)\n",
    "#     #plot confusion matrix\n",
    "#     fig, ax = plt.subplots(figsize=(10,10))\n",
    "#     cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "#     sns.heatmap(m_df, annot=True, linewidths=.5,ax=ax,fmt='.2f',cmap = cmap)\n",
    "#     ax.set_xlabel('Predicted')\n",
    "#     ax.set_ylabel('Actual')\n",
    "#     ax.figure.savefig('Figures/RF_CM_Param_'+str(i)+ '_' + str(l) +'_'+str(round(a,3))+'_.jpg',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of the  decision tree in forest\n",
    "n_tree = [20,40,60,100,200,400,600,1000,1200,1400]\n",
    "# those two criterion almost make no difference to overall acuracy,  too complicated to examine their impact on each category\n",
    "# so just use the default gini index\n",
    "#crit = ['gini','entropy']\n",
    "# minimum number of samples in the leaf (end node)\n",
    "min_leaf = [1,3,5,7,9,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y1 = []\n",
    "for l in range(len(min_leaf)):\n",
    "    a, oob = RandomForest(100, min_leaf[l],learn_df2)\n",
    "    print(\"===========================================\")\n",
    "    print('Overall acuracy: ' +str(a))\n",
    "    print('Out-of-bag score: ' +str(oob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(min_leaf,y1)\n",
    "plt.legend( ['Accuracy','Out-of-bag score'])\n",
    "plt.xlabel(\"min_samples_leaf\")\n",
    "plt.savefig('oob1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we see the larger is the min_samples_leaf, the larger is the gap between the accuracu and out of bag scorem which indicates that the worse the model fitted to the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y2 = []\n",
    "for i in range(len(n_tree)):\n",
    "    a, oob = RandomForest(n_tree[i], 1,learn_df2)\n",
    "    y2.append((a,oob)) \n",
    "    print(\"===========================================\")\n",
    "    print('Overall acuracy: ' +str(a))\n",
    "    print('Out-of-bag score: ' +str(oob))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(n_tree,y2)\n",
    "plt.legend( ['Accuracy','Out-of-bag score'])\n",
    "plt.xlabel(\"n_tree\")\n",
    "plt.savefig('oob2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot above, the larger the forest is, the smaller is the gap  between OOB score and the accuracy, which means the better the classifier fitted to the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
